Rozwiązania dostarczone z niniejszą pracą stanowią konglomerat kilku technologii programistycznych, których celem jest dostarczenie narzędza służącego przeprowadzaniu równoległych operacji szybkiego mnożenia macierzy dla dużych danych wejściowych oraz prezentacji wydajności takich operacji w dokumentach \LaTeX \, (rozdział \ref{ch:performance}). 

\subsubsection{Program \texttt{pmm}}

Trzon projektu stanowi program \texttt{pmm}. Dostarcza on wygodny interfejs użytkownika pozwalający na przeprowadzenie operacji mnożenia macierzy na dowolnych dwóch plikach reprezentujących macierz w zapisie wierszowym. W zależności od wyboru metody mnożenia operacje przebiegają sekwencyjne lub równolegle.

Interesująca z puntku widzenia obliczeń rozproszonych jest implementacja algorytmów Cannona\footnote{Odnosząc się do listingu \ref{ls:pmm_help} mowa o algorytmach: \texttt{cannon}, \texttt{cannon\_dgemm}, \texttt{cannon\_omp}}. Z racji, że ich implementacja jest analogicznia (z dokładnością do obliczeń drobnoziarnistych i rezerowania większej ilości pamięci na ich cele) omówimy tylko implementację klasycznego algorytmu. Ich działanie zasadza się na wyborze jednego wyróżnionego węzła nadzorcy (dalej nazywanego po prostu \emph{nadzorcą}), którego zadaniem jest inicjalizacja obliczeń oraz zebranie wyników z wszystkich węzłów sieci po ich zakończeniu. Proces inicjalizowania polega na wczytaniu do pamięci lokalnej węzła danych wejściowych\footnote{Rozwiązanie to ma swoje wady i swoje zalety. Przede wszystkim wymaga wiele pamięci lokalnej w węźle. Rozwiązaniem alternatywnym byłoby mapowanie plików (\texttt{mmap}) i rozsyładnie ich po fragmencie do innych węzłów bezpośrednio po zbuforowaniu. Wadą tego rozwiązania jest utrudnione wstępne przetwarzanie (skalowanie macierzy, interpretacja szerokości i długości) przy zachowaniu wierszowego zapisu macierzy.} (plików zawierających elementy macierzy). 

\begin{listing}[H]
\inputminted[fontsize=\footnotesize,bgcolor=bg,linenos,firstnumber=365,firstline=365,lastline=377]{c}{includes/listings/main.c}
\caption{Plik \texttt{main.c}; definiowanie bloków macierzy}
\label{l:block_size}
\end{listing}

Na listingu \ref{l:block_size} zaprezentowany jest fragment kodu odpowiedzialny za wyznaczanie rozmiaru bloków macierzy wejściowych do rozesłania do innych węzłów sieci. W linijkach \((365-367)\) określany jest największy Spośród wymiarów macierzy podanych przez użytkownika\footnote{Wykorzystuje się tutaj fakt, że operator przypisania ,,\texttt{=}'' zwraca wartość przypisania.}. W linijkach \((369-374)\) określana jest szerokość bloku macierzy (zmienna \texttt{sz}), liczba elementów w bloku (zmienna \texttt{blockSz}) oraz szerokość całej macierzy po uwzględnieniu skalowania (zmienna \texttt{max}).

Nadzorca decyduje o skalowaniu macierzy w zależności od wymiarów torusa\footnote{Szerokośc i wysokość torusa muszą być takie same; w przeciwnym wypadku obliczenie jest przerywane.}, na którym przeprowadzane są obliczenia. Zadanie węzła nadzorującego kończy się na tym etapie zdefiniowaniem typu \texttt{MPI\_SUBMATRIX}, który w dalszej części będzie służył do wysyłania komunikatów w sieci zawierających odpowiednie podmacierze.

Wszystkie argumenty dostarczone przez użytkownika przechowywane są w strukturze \texttt{arguments}. Wspomniane skalowanie macierzy wejściowych ma miejsce wówczas, gdy wymiary macierzy dostarczone przez użytkownika nie są równe (macierze nie są kwadratowe) oraz ich szerokość nie jest wielokrotnością szerokości sieci w topologii torusa. Decydują o tym instrukcje zamieszczone w listingu \ref{l:matrix_scaleup}.

\begin{listing}[H]
\inputminted[fontsize=\footnotesize,bgcolor=bg,linenos,firstnumber=408,firstline=408,lastline=418]{c}{includes/listings/main.c}
\caption{Plik \texttt{main.c}; warunek skalowania macierzy}
\label{l:matrix_scaleup}
\end{listing}

Skalowanie odbywa się w trakcie wczytywania macierzy przez nadzorcę w procedurze \texttt{load\_matrix}. Decyduje o tym ostatni ostatni z argumentów formalnych.

Na tym etapie rozpoczynamy właściwą część algorytmu polegającą na rozdystrybuowaniu macierzy blokowej do węzłów sieci. Na potrzebę objaśnienia dalszej części implementacji powiedzmy, że chcemy obliczyć iloczyn pewnych macierzy kwadratowych \(A\), \(B\) składających się z dziewięciu bloków \(A_{ij}\, B_{ij}\) o równych wymiarach. Klasyczna wersja algorytmu omawiana w \cite{Stpiczynski}, \cite{Czech}, \cite{Golub} zakłada wstępnie rozdystrybuowanie podmacierzy w sposób przedstawiony na rysunku \ref{fig:cannon_src1} i następnie przeprowadzenie odpowiednich przesunięć podmacierzy między węzłami sieci do stanu przedstawionego na rysunku  \ref{fig:cannon_src2}. 
\begin{figure}[H]
\centering
\begin{tabular}{|cc|cc|cc|}
\hline
\(A_{11}\) & \(B_{11}\) & \(A_{12}\) & \(B_{12}\) & \(A_{13}\) & \(B_{31}\) \\
\hline
\(A_{21}\) & \(B_{21}\) & \(A_{22}\) & \(B_{22}\) & \(A_{23}\) & \(B_{23}\) \\
\hline
\(A_{31}\) & \(B_{31}\) & \(A_{32}\) & \(B_{32}\) & \(A_{33}\) & \(B_{33}\) \\
\hline
\end{tabular}
\caption{Klasyczne wejściowe rozmieszczenie macierzy blokowych \(A_{ij}\) i \(B_{ij}\)} 
\label{fig:cannon_src1}
\end{figure}

\begin{figure}[H]
\centering
\begin{tabular}{|cc|cc|cc|}
\hline
\(A_{11}\) & \(B_{11}\) & \(A_{12}\) & \(B_{22}\) & \(A_{13}\) & \(B_{33}\) \\
\hline
\(A_{22}\) & \(B_{21}\) & \(A_{23}\) & \(B_{32}\) & \(A_{21}\) & \(B_{21}\) \\
\hline
\(A_{33}\) & \(B_{31}\) & \(A_{31}\) & \(B_{12}\) & \(A_{33}\) & \(B_{32}\) \\
\hline
\end{tabular}
\caption{Proponowane wejśćiowe rozmieszczenie macierzy blokowych \(A_{ij}\) i \(B_{ij}\)} 
\label{fig:cannon_src2}
\end{figure}

Operację tę można uprościć przechodząc bezpośrednio do rozmieszczenia podmacierzy w sieci takiego jak na rys. \ref{fig:cannon_src2}. Rozpatrzmy kod zamieszczony na listingu \ref{l:start_dist_cannon}. Zawarte w nim instrukcje wykonywane są tylko przez nadzorcę i dotyczą wyłącznie dystrybucji macierzy \(A\).

Aby zrozumieć ideę stojącą za tą częścią kodu sprowadźmy dla przykładu problem do obliczeń na torusie \(3\times 3\) i macierzy kwadratowej \(A\) złożonych z dziewięciu bloków \(A_{ij}\) równego wymiaru. Jeśli tablicę \texttt{proclA} zinterpretujemy jako macierz \(3\times 3\) w zapisie wierszowym, wówczas obrazowo przedstawia ją rysunek \ref{fig:proclA}.

\begin{figure}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
0 & 1 & 2 \\
\hline
5 & 3 & 4 \\
\hline
7 & 8 & 6 \\
\hline
\end{tabular}
\caption{Tablica pomocnicza \texttt{proclA}}
\label{fig:proclA}
\end{figure}
% Instrukcje w liniach \(455,\456,\,459,\,477,\,478\) służą pomiarow czasu wykonania wybranych części kodu i nie są istotne dla omówianego zagadnienia.

\begin{listing}[H]
\inputminted[fontsize=\footnotesize,bgcolor=bg,linenos,firstnumber=443,firstline=443,lastline=485]{c}{includes/listings/main.c}
\caption{Plik \texttt{main.c}; wstępne rozmieszczanie macierzy}
\label{l:start_dist_cannon}
\end{listing}

Matematycznie rzecz ujmująć zdefiniowaliśmy w ten sposób permutację między indeksami tabeli, a zbiorem \(\{0, 1, \dots, 8\}\):
\begin{equation*}
f\colon \left\{\begin{aligned}
& 0\mapsto 0, & \quad 1\mapsto 1, & \quad 2\mapsto 2, \\
& 3\mapsto 5, & \quad 4\mapsto 3, & \quad 5\mapsto 4, \\
& 6\mapsto 7, & \quad 7\mapsto 8, & \quad 8\mapsto 6. \\
\end{aligned}\right.
\end{equation*}
inaczej \(f=\bigl(\begin{smallmatrix}
  0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
  0 & 1 & 2 & 5 & 3 & 4 & 7 & 8 & 6
\end{smallmatrix}\bigr)\).

\noindent Aby zrozumieć pętlę \texttt{for} w liniach (\(458-485\)) 
ponumerujmy podmacierze \(A_{ij}\):

\begin{equation*}
g\colon \left\{\begin{aligned}
A_{11}&\mapsto 0, & A_{12}&\mapsto 1, & A_{13}&\mapsto 2, \\
A_{21}&\mapsto 3, & A_{22}&\mapsto 4, & A_{23}&\mapsto 5, \\
A_{31}&\mapsto 6, & A_{32}&\mapsto 7, & A_{33}&\mapsto 8. \\
\end{aligned}\right.
\end{equation*}


Permutacja \(f\) jest nieprzypadkowa, gdyż jeśli rozważymy teraz wartość \(f(g(A_{ij})\), otrzymamy identyfikator procesu, do którego należy wysłać macierz \(A_{ij}\). Innymi słowy odwzorowanie \(f\) jest odpowiedniością między częściami macierzy (wartościami funkcji \(g\)), a identyfikatorami procesów.

Pętla \texttt{for} zawarta w liniach (458-485) iteruje się po zmiennej \texttt{proc}, która odpowiada wyżej zdefiniowanym wartościom funkcji \(g\). Należy rozumieć przez to, że dla \(\mathtt{proc}=i\) przetwarzamy do wysłania blok \(A_{ij}=g^{-1}(i)\).


Tablica \texttt{displacements} definiowana w ciele pętli (linie 462-468) zawiera indeksy pierwszych elementów każdego wiersza podmacierzy tablicy \texttt{A}\footnote{Tablica \texttt{A} przechowuje wszystkie elementy macierzy \(A\) w węźle nadzorczym.}, które z kolei służą do przepisywania odpowiednich elementów do bufora \texttt{pA} (linie 471-476). Ostatecznie bufor \texttt{pA} zawierający blok \(g^{-1}(\mathtt{proc})\) jest wysyłany do węzła \(f(g(A_{ij}))\) (procedura \texttt{MPI\_Send}, linia 482). Pętla jest skonstruowana tak, że po jej wykonaniu nadzorca posiada przypadający mu blok macierzy bez zbędnego wysyłania go do siebie (warunek w lini 481). 


Równolegle z przygotowywaniem komunikatów przez nadzorcę, pozostałe procesory przygotowują się do odebrania przeznaczonych im komunikatów. Tym sposobem otrzymujemy rozkład macierzy \(A\) przedstawiony na rysunku \ref{fig:cannon_src2}.